{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Classification problems form a collection of machine learning problems that require the algorithm to idenitfy which class a data point belongs to.\n",
    "\n",
    "The simplest form of classification is *binary* classification. Here there are only two possible classes, usually '0' and '1'. The algorithm then aims to find a *decision boundary* that accurately splits up the two classes in feature space.\n",
    "\n",
    "*Multi-class* classification is the set of problems where each data point can belong to one of many classes (here many means more than 2). These problems often require slightly different algorithms compared to binary classification, incorporating tricks like the *one-vs-all* or *one-vs-one* methods.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Logistic regression is an example of a binary classification algorithm. It works in a similar way to linear regression, except that the output is manipulated to give a binary output and the loss function is adjusted to work for classification.\n",
    "\n",
    "An example dataset is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Datapoint:  [array([2, 7]) 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the features, the independent variables. This example has two features.\n",
    "x = np.array([[2,7],[1,1],[3,18],[2,5],[1,2],[3,10]])\n",
    "\n",
    "# Define the labels, the dependent variables\n",
    "y = np.array([1,0,1,1,0,1])\n",
    "\n",
    "# A single data point is then:\n",
    "p1 = np.array([x[0], y[0]])\n",
    "print('Example Datapoint: ', p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with linear regression, the first thing to define is our *hypothesis function*. Here we ensure that the output of our classification algorithm is between 0 and 1:\n",
    "\n",
    "`0 <= h(theta) <= 1`\n",
    "\n",
    "This ensures that the output can easily be converted into a prediction of which class the data point belongs to by setting a threshold on the output of the hypothesis function. Usually by default this threshold is set at 0.5\n",
    "\n",
    "In logistic regression the hypothesis function is converted to a value between 0 and 1 by using the *sigmoid* function. This is the function\n",
    "\n",
    "`1 / (1+exp(z))`\n",
    "\n",
    "and is available in scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "# Our hypothesis function estimates the dependent variable\n",
    "def hypothesis_function(x, theta_0, theta_1):\n",
    "    return expit(theta_0 + np.matmul(x, theta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will produce an estimate for the label of the data point based on the features and the parameters `theta_1` and `theta_2`. An example with dummy values for `theta_0` ad `theta_1` is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate:  [ 0.9999546   0.95257413  1.          0.99966465  0.98201379  0.99999917]\n",
      "Actual:  [1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "theta_0 = 1\n",
    "theta_1 = np.array([1,1]) # One parameter for each feature\n",
    "\n",
    "# Our hypothesis function\n",
    "estimate_y = hypothesis_function(x, theta_0, theta_1)\n",
    "\n",
    "print('Estimate: ', estimate_y)\n",
    "print('Actual: ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the output of our hypothesis function is between 0 and 1, we can assume that it represents the *probability* that the data point input belongs to the class `1`. Therefore if the output is 0.7, it can be said that this represents a probability of 70% that this example belongs to class `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "As with linear regression, we need to find a method to automatically find the values of the parameters `theta_0` and `theta_1` that predict the classes of the data points with the highest accuracy. As before, this requires the definition of a *loss function* that can be minimised using the gradient descent algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, estimate_y):\n",
    "    return np.mean(-y*np.log(estimate_y) + -(1-y)*np.log(1-estimate_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with linear regression, our loss function measures how well our predictions match the actual labels on our data. Our choice of loss function is such that the worse our prediction, the higher the penalty.\n",
    "\n",
    "If the label is 1, then the loss function looks like the following for different outputs of the hypothesis function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fce9a2e5898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce9a39e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = (np.arange(49)+1)/50.\n",
    "loss = np.empty(49)\n",
    "\n",
    "for i in range(49):\n",
    "    loss[i] = loss_function(1, z[i])\n",
    "\n",
    "plt.plot(z, loss)\n",
    "plt.xlabel('hypothesis value')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively if the label is 0, the loss looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fce9a3a5b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndGpVtD1j+gUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fce9a2889b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = (np.arange(49)+1)/50.\n",
    "loss = np.empty(49)\n",
    "\n",
    "for i in range(49):\n",
    "    loss[i] = loss_function(0, z[i])\n",
    "\n",
    "plt.plot(z, loss)\n",
    "plt.xlabel('hypothesis value')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of cost function therefore gives a useful feedback as to how well our hypothesis function is currently performing. Additionally, it can be shown that this cost function results in a *convex* function, allowing us to use gradient descent and find the one global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.17785315276\n"
     ]
    }
   ],
   "source": [
    "theta_0 = 1\n",
    "theta_1 = np.array([1,1]) # One parameter for each feature\n",
    "\n",
    "estimate_y = hypothesis_function(x, theta_0, theta_1)\n",
    "\n",
    "loss = loss_function(y, estimate_y)\n",
    "print('Loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The same gradient descent update rule can be used that was introduced in linear regression:\n",
    "\n",
    "theta_i := theta_i - alpha * grad(loss_function w.r.t. theta_i)\n",
    "\n",
    "Calculating the gradient of our loss function results in the following gradient descent update rule for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update(x, y, theta_0, theta_1, learning_rate=0.01):\n",
    "    new_theta_0 = theta_0 - learning_rate * (np.sum(hypothesis_function(x, theta_0, theta_1) - y, axis=0) / len(y))\n",
    "    new_theta_1 = theta_1 - learning_rate * (np.matmul((hypothesis_function(x, theta_0, theta_1) - y), x) / len(y))\n",
    "    return new_theta_0, new_theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this update rule is *exactly the same* as the update rule for linear regression, just with a different hypothesis function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this update rule defined, we have everything we need to perform binary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_0:  -5.30408731214\n",
      "theta_1:  [-1.84584055  2.42379972]\n",
      "Final Loss:  0.0245959476373\n"
     ]
    }
   ],
   "source": [
    "# Initialise parameter values\n",
    "theta_0 = 1\n",
    "theta_1 = np.array([1,1])\n",
    "\n",
    "# Gradually update the parameter values\n",
    "n = 0\n",
    "while n < 20000:\n",
    "    theta_0, theta_1 = gradient_descent_update(x, y, theta_0, theta_1)\n",
    "    n += 1\n",
    "    \n",
    "print('theta_0: ', theta_0)\n",
    "print('theta_1: ', theta_1)\n",
    "print('Final Loss: ', loss_function(y, hypothesis_function(x, theta_0, theta_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output final loss suggests that the algorithm has converged, and we can check by comparing the predicted values against the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(x, theta_0, theta_1, threshold = 0.5):\n",
    "    return 1*np.greater_equal(hypothesis_function(x, theta_0, theta_1), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels:  [1 0 1 1 0 1]\n",
      "Predicted labels:  [1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print('Actual labels: ', y)\n",
    "predicted_labels = predict_labels(x, theta_0, theta_1)\n",
    "print('Predicted labels: ', predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then measure the accuracy on the training set as the number of correctly classified data points divided by the total number of data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100*np.sum(y==predicted_labels)/len(y)\n",
    "print('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Here we will use the *one-vs-all* paradigm to apply the logistic regression algorithm above to a multi-class setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Datapoint:  [array([2, 7]) 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the features, the independent variables. This example has two features.\n",
    "x = np.array([[2,7],[1,1],[3,18],[2,5],[1,2],[3,10]])\n",
    "\n",
    "# Define the labels, the dependent variables\n",
    "y = np.array([1,0,2,1,0,2])\n",
    "\n",
    "# A single data point is then:\n",
    "p1 = np.array([x[0], y[0]])\n",
    "print('Example Datapoint: ', p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot directly apply our logistic regression algorithm to this problem as our loss function was defined explicitly for the binary case where our label was either 0 or 1\n",
    "\n",
    "The one-vs-all paradigm involves reducing the set of classes into multiple binary classification problems. This is done by setting all classes except for one to be the *negative* class, and the target class as the *positive* class, and then repeating this to find a decision boundary for each class in turn\n",
    "\n",
    "To then classify the point, we select the class that gives the maximum likelihood from all of the trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.31106484 -2.04777234 -6.79007285]\n",
      "[[ 2.07723007  1.76489344 -1.52059359]\n",
      " [-2.52525259 -0.31958367  1.26753184]]\n"
     ]
    }
   ],
   "source": [
    "possible_classes = [0,1,2]\n",
    "\n",
    "# Initialise parameter values\n",
    "theta_0 = np.ones(len(possible_classes))\n",
    "theta_1 = np.array([np.ones(len(possible_classes)),np.ones(len(possible_classes))])\n",
    "\n",
    "for i in range(len(possible_classes)):\n",
    "    new_y = np.array([])\n",
    "    for label in y:\n",
    "        if label==possible_classes[i]:\n",
    "            new_y = np.append(new_y, 1)\n",
    "        else:\n",
    "            new_y = np.append(new_y, 0)\n",
    "\n",
    "    # Gradually update the parameter values\n",
    "    n = 0\n",
    "    while n < 20000:\n",
    "        theta_0[i], theta_1[:,i] = gradient_descent_update(x, new_y, theta_0[i], theta_1[:,i])\n",
    "        n += 1\n",
    "        \n",
    "print(theta_0)\n",
    "print(theta_1)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trained the three seperate binary classifiers, we can predict the label of each data point by taking the maximum output of the classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_multiclass(x, theta_0, theta_1):\n",
    "    max_value = np.zeros(len(x))\n",
    "    predicted_label = -1*np.ones(len(x))\n",
    "    for i in range(len(theta_0)):\n",
    "        value = hypothesis_function(x, theta_0[i], theta_1[:,i])\n",
    "        for j in range(len(x)):\n",
    "            if value[j] > max_value[j]:\n",
    "                max_value[j] = value[j]\n",
    "                predicted_label[j] = i\n",
    "            \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels:  [1 0 2 1 0 2]\n",
      "Predicted labels:  [ 1.  0.  2.  1.  0.  2.]\n",
      "Accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Actual labels: ', y)\n",
    "predicted_labels = predict_labels_multiclass(x, theta_0, theta_1)\n",
    "print('Predicted labels: ', predicted_labels)\n",
    "\n",
    "accuracy = 100*np.sum(y==predicted_labels)/len(y)\n",
    "print('Accuracy: ', accuracy, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML_Coursera]",
   "language": "python",
   "name": "conda-env-ML_Coursera-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
